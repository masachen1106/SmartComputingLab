{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7282a652",
   "metadata": {},
   "source": [
    "# Selenium 肝癌衛教資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459d7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import json, os, pprint, time\n",
    "from urllib import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45f60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The browser has been opened.\n"
     ]
    }
   ],
   "source": [
    "# 設定 ChromeDriver 的路徑\n",
    "s = Service(\"C:\\Program Files\\Google\\Chrome\\Application\\chromedriver.exe\")\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")#無視窗模式\n",
    "options.add_argument('--disable-popup-blocking') #禁止所有跳出視窗\n",
    "driver = webdriver.Chrome(service=s, options=options)\n",
    "print(\"The browser has been opened.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13bdbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "listData = []\n",
    "url = 'https://livercancer.com.tw/ques.php'\n",
    "\n",
    "#進入網址\n",
    "def visit():\n",
    "    driver.get(url)\n",
    "#找到我們要的內容\n",
    "def getMainLinks():\n",
    "    a_elms = driver.find_elements(By.CSS_SELECTOR, 'a[class=\"ques-list\"]')\n",
    "    for a in a_elms:\n",
    "        listData.append({\n",
    "            'title':a.get_attribute('innerText'),\n",
    "            'link':a.get_attribute('href')\n",
    "        })\n",
    "def getContent():\n",
    "    for i in range(len(listData)):\n",
    "        if 'content' not in listData[i]:\n",
    "            listData[i]['content'] = []\n",
    "        driver.get(listData[i]['link'])\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, 'div[class=\"col-lg-8 col-12 ques-detail-ans\"] > p')\n",
    "                )\n",
    "            )\n",
    "            a_elms = driver.find_elements(By.CSS_SELECTOR, 'div[class=\"col-lg-8 col-12 ques-detail-ans\"] > p')\n",
    "            for a in a_elms:\n",
    "                listData[i]['content'].append(a.get_attribute('innerText'))\n",
    "                \n",
    "        except TimeoutException as e:\n",
    "            continue\n",
    "            \n",
    "def saveJason():\n",
    "    fp = open('livercancer.json', 'w', encoding = 'utf-8')\n",
    "    fp.write(json.dumps(listData, ensure_ascii = False))\n",
    "    fp.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b494c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    visit()\n",
    "    getMainLinks()\n",
    "    getContent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "881fdfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '許多名人發現肝癌時都是末期，且都因肝癌而過世，得了肝癌就只能束手無策嗎？\\n×',\n",
       "  'content': ['肝癌是否會引發症狀，視腫瘤的位置、大小和數量而定，舉例來說，由於肝臟本體沒有痛覺神經，只有在表面有少數痛覺神經分布，若腫瘤不是長在肝臟表面，通常不會造成疼痛，也就難以察覺。此外，肝癌的症狀大多不具特異性，如：腹脹、食慾不振、體重減輕，容易和其他腸胃道疾病混淆，所以往往在發現時已是中晚期。所幸肝癌可以透過血清胎兒蛋白(AFP)和腹部超音波來早期篩檢，所以建議高危險族群，如B型或C型肝炎患者應定期接受檢查。']},\n",
       " {'title': '究竟肝癌會不會復發或轉移？發生的可能性有多高？\\n×',\n",
       "  'content': ['相對於其他癌症，肝癌確實較容易復發。肝癌復發機率的高低是受到多重因素影響，除了肝腫瘤的分布、大小和數量，治療前肝硬化程度，還有是否移除慢性肝炎的原因。由於在台灣許多肝癌是由慢性B型或C型肝炎一路演變而來，雖然以手術去除肝臟腫瘤，體內還是有B型或C型肝炎病毒存在，如果沒有同時治療B型或C型肝炎，日後肝癌復發的機率相對較高。',\n",
       "   '至於會不會轉移，會轉移到哪裡，也是視肝腫瘤長的位置和形狀而定。舉例來說，如果腫瘤較靠近肝門靜脈，且無包膜、邊緣不規則，比較容易經由肝內血管轉移到肝內其他地方，稱為「肝內轉移」。如果腫瘤的位置比較靠近下腔靜脈，會比較容易透過下腔靜脈的血流擴散到身體其他部位，稱為「肝外轉移」。',\n",
       "   '轉移的部位不同，有可能出現不同的症狀，或根本沒有症狀。譬如：轉移到肺臟，有可能出現咳嗽、喘；而轉移到骨頭，有可能引發骨骼疼痛。因此，肝癌治療後的定期追蹤檢查相當重要，同時也要對身體異狀保持警覺性，萬一發現有復發或轉移的徵兆，才能及早治療。']},\n",
       " {'title': '斷食、禁食，能餓死癌細胞？\\n×',\n",
       "  'content': ['不能。在正規治療外，癌症患者需要足夠的營養，才有體力做為後盾去面對治療。若是採用禁食或斷食療法，全身上下的細胞都會受影響，並不能只餓到癌細胞；反而會使正常細胞營養不足而無法正常運作，更容易遭受癌細胞的攻擊，恐怕在餓死癌細胞前，先餓死自己。因此，斷食或禁食並不能餓死癌細胞。']},\n",
       " {'title': '不能吃肉，否則會養大癌細胞？\\n×',\n",
       "  'content': ['截至目前為止，並沒有足夠的研究資料顯示，吃肉類或是吃得太營養，會把癌細胞養大，反而在臨床上，常見到病患為了把癌細胞餓死，吃的量不夠、又不吃肉而導致營養不良。肉類是重要的蛋白質來源之一，而蛋白質是構成體內肌肉和免疫抗體的主要成分，如果為了怕養大癌細胞而不吃肉，有可能會影響到體力和免疫力。',\n",
       "   '如同其他癌症，肝癌患者的飲食原則也是以均衡營養、自然清淡為主。由於肝臟機能已經受損，飲食上要注意避免增加肝臟負擔，所以該攝取多少蛋白質、攝取何種蛋白質，應按病人個別狀況來調整。舉例來說，曾發生肝性腦病變(肝昏迷)的患者，就需要採低蛋白飲食，並且盡量選擇含氨量較低的植物性蛋白，除了有較好的利用，也能同時增加纖維的攝取；而剛完成肝臟手術的患者，則需增加優質蛋白質的攝取，幫助術後組織修復。如在飲食上有疑問，應諮詢營養師門診，請營養師依照每個人的狀況，提供個人化建議。']},\n",
       " {'title': '肝癌會遺傳嗎？\\n×',\n",
       "  'content': ['確實，家中有人罹患肝癌，其他家人罹患肝癌的機率比一般人高出10倍左右，但並不是透過基因遺傳給下一代，而是由B型肝炎在家庭內的傳播，以及家庭飲食習慣造成。',\n",
       "   '台灣的肝癌患者大多是由B型肝炎一路演變過來，而B肝的感染，主要是透過母子垂直感染，或者是傷口、黏膜接觸帶有病毒的血液、體液，造成的水平傳染，如：共用牙刷、刮鬍刀、性行為。台灣早期B型肝炎的篩檢和疫苗施打尚未普及，容易發生家中多人感染B型肝炎、之後陸續演變成肝癌的情況，所以才會有「肝癌會遺傳」的錯誤印象。',\n",
       "   '此外，攝取遭黃麴毒素汙染的花生、或過量飲酒，也是肝癌的危險因子，這些飲食習慣可能是受家庭的影響而形成。肝癌的發生是由多種因素綜合而成，所以，若有家人罹患肝癌，建議其他家人也去進行相關檢查，才能及早發現、控制，避免開啟「肝炎---肝硬化---肝癌」的肝癌三部曲。']},\n",
       " {'title': '吃保肝產品，能保護肝臟健康，避免復發？\\n×',\n",
       "  'content': ['市面上的保肝產品，多半是以能夠抗氧化或是增強免疫系統功能，以及幫助促進患者體力等為主軸，健康的人服用這些產品，也許無傷大雅，可作為日常保養之用；但對於肝癌患者來說，可要小心謹慎使用，建議肝癌患者不可自行服用保肝產品，並且要在醫師指示下積極治療，才不會因為胡亂服用保肝產品，導致交互作用，降低正規治療的成效。']},\n",
       " {'title': '動手術會讓癌細胞擴散出去，是真的嗎？\\n×',\n",
       "  'content': ['不會。癌細胞並不會因為開刀而擴散出去。台灣肝癌手術的技術已經非常成熟、經驗也相當豐富，還有很多能夠提升手術精準度的方法，因此，患者大可放心的接受手術治療，如果醫師評估需要開刀，一定要按照醫囑，千萬不要因為害怕開刀讓癌細胞擴散，或聽信偏方尋求另類治療，如此，反而會錯失治療的機會。']},\n",
       " {'title': '醫師說我的肝癌不用開刀，表示沒救了嗎？\\n×',\n",
       "  'content': ['肝癌的治療方式相當多樣，像是栓塞治療，是堵住供應肝癌營養的血管、讓腫瘤因缺乏養分而壞死，並不是只能以手術切除。所以不用開刀不代表沒救，而是醫師在評估腫瘤位置、大小和數量後，決定最適合以哪種方式來治療。']},\n",
       " {'title': '癌症治療前要補充營養，才有體力抗癌？\\n×',\n",
       "  'content': ['大多數的肝癌患者在治療前，就因為心情和疾病本身，造成食慾不佳，營養不良；治療期間又因為治療副作用，出現噁心、想吐等阻礙進食的情況；再加上癌症本身是ㄧ種高消耗能量的狀況，因此，癌症病患的體重多少會直直落，缺乏體力繼續療程。一般而言，會希望癌症病人在開始治療前，透過攝取適當的營養，儲備治療時的體力，但是，肝癌患者在補充營養時，需特別注意，應控制熱量及高脂肪食物的攝取，因為過多的熱量和脂肪容易造成脂肪肝，反而不利於後續治療。該攝取多少熱量，何時應該加入營養補充品，也可以諮詢營養師，得到完整的資訊。']},\n",
       " {'title': '標靶藥物僅能延長壽命，無法治癒？\\n×',\n",
       "  'content': ['標靶治療的治療原理，是針對癌細胞特性，透過阻斷癌細胞特有的突變、增殖、擴散或血管新生等機轉，使腫瘤細胞縮小或抑制腫瘤增生。',\n",
       "   '相較於其他癌症，肝癌較容易復發，所以若能以外科方式根除，治療還是以外科方式為主。標靶藥物通常用在肝臟腫瘤無法以外科方式處理，或者已經轉移到肝臟以外時使用，目的在減緩腫瘤惡化、縮小腫瘤，進而延長存活時間。']}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(listData)):\n",
    "    try:\n",
    "        del listData[i]['link']\n",
    "    except:\n",
    "        continue\n",
    "listData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a992f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveJason():\n",
    "    \n",
    "    fp = open('livercancer.json', 'w', encoding = 'utf-8')\n",
    "    fp.write(json.dumps(listData, ensure_ascii = False))\n",
    "    fp.close()\n",
    "    \n",
    "saveJason()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b059ae-dc8d-4050-ad9f-53bde62ae439",
   "metadata": {},
   "source": [
    "# 利用TF-IDF萃取關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9de1cd-e6e7-4893-a6c7-30271eeb9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install snownlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9406b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['相', '較', '於', '其他', '癌症', '，', '肝', '癌', '較', '容', '易', '復', '發', '，', '所以', '若', '能', '以', '外科', '方式', '根除', '，', '治', '療', '還', '是', '以', '外科', '方式', '為', '主', '。', '標', '靶', '藥物', '通常', '用', '在', '肝', '臟', '腫', '瘤', '無', '法', '以', '外', '科', '方', '式', '處', '理', '，', '或', '者', '已', '經', '轉移', '到', '肝', '臟', '以', '外', '時', '使用', '，', '目', '的', '在', '減', '緩', '腫瘤', '惡化', '、', '縮', '小', '腫瘤', '，', '進', '而', '延', '長', '存', '活', '時', '間', '。']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from snownlp import SnowNLP\n",
    "# 定義文本列表\n",
    "text_list = '相較於其他癌症，肝癌較容易復發，所以若能以外科方式根除，治療還是以外科方式為主。標靶藥物通常用在肝臟腫瘤無法以外科方式處理，或者已經轉移到肝臟以外時使用，目的在減緩腫瘤惡化、縮小腫瘤，進而延長存活時間。'\n",
    "\n",
    "# 創建SnowNLP對象\n",
    "s = SnowNLP(text_list)\n",
    "seg_list = s.words\n",
    "\n",
    "\n",
    "# 輸出斷詞結果\n",
    "print(seg_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34bba96b-3759-40a0-abe7-5ab1c000da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['通常', '轉移', '藥物', '腫瘤', '癌症', '根除', '方式', '所以', '惡化', '外科']\n"
     ]
    }
   ],
   "source": [
    "# 創建TfidfVectorizer對象並擬合\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(seg_list)\n",
    "\n",
    "# 獲取特徵詞列表\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# 獲取第一篇文章的特徵詞權重列表\n",
    "tfidf_weights = tfidf_vector[0].toarray()[0]\n",
    "\n",
    "# 找出前N個最重要的關鍵詞\n",
    "top_n = 10\n",
    "indices = tfidf_weights.argsort()[-top_n:][::-1]\n",
    "top_keywords = [feature_names[i] for i in indices]\n",
    "\n",
    "# 輸出結果\n",
    "print(top_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda6b0e-3e6b-4442-a64c-3b4a0d89e073",
   "metadata": {},
   "source": [
    "# CSV轉JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a731d771-598c-45ca-a0d5-4aedb1750e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "excel_file = r'C:\\Users\\user\\Desktop\\碩論\\chatgpt衛教\\data.xlsx'\n",
    "json_file = 'output.json'\n",
    "\n",
    "# 讀取Excel檔案\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "data = []\n",
    "\n",
    "# 將每一行轉換成JSON格式\n",
    "for _, row in df.iterrows():\n",
    "    item = {\n",
    "        \"instruction\": row[\"title\"],\n",
    "        \"input\": \"\",\n",
    "        \"output\": row[\"content\"]\n",
    "    }\n",
    "    data.append(item)\n",
    "\n",
    "# 寫入JSON檔案\n",
    "with open(json_file, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(data, jsonfile, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e209ba9-b69a-4ff4-a03e-6ceafedc07bb",
   "metadata": {},
   "source": [
    "# PolitiFact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e70eb8-46bb-4d4d-afdd-4425a0989709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"            \\ndef saveJason():\\n    fp = open('livercancer.json', 'w', encoding = 'utf-8')\\n    fp.write(json.dumps(listData, ensure_ascii = False))\\n    fp.close()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listData = []\n",
    "url = 'https://www.politifact.com/factchecks/list/?category=coronavirus'\n",
    "url2 = 'https://www.politifact.com/factchecks/list/?page=2&category=coronavirus'\n",
    "#進入網址\n",
    "def visit(x):\n",
    "    if x == 0 :\n",
    "        driver.get(url)\n",
    "    else:\n",
    "        driver.get(f'https://www.politifact.com/factchecks/list/?page={x+1}&category=coronavirus')\n",
    "#找到我們要的內容\n",
    "def getMainLinks():\n",
    "    a_elms = driver.find_elements(By.CSS_SELECTOR, 'a[class=\"m-statement__quote\"]') #content & link\n",
    "    b_elms = driver.find_elements(By.CSS_SELECTOR, 'img[class=\"c-image__original \"]') #label\n",
    "    c_elms = driver.find_elements(By.CSS_SELECTOR, 'a[class=\"m-statement__name\"]') #source\n",
    "    d_elms = driver.find_elements(By.CSS_SELECTOR, 'footer[class=\"m-statement__footer\"]') #time_stamp\n",
    "    for a, b ,c ,d in zip(a_elms, b_elms[1::2], c_elms, d_elms):\n",
    "        listData.append({\n",
    "            'content':a.get_attribute('innerText'),\n",
    "            'link':a.get_attribute('href'),\n",
    "            'label':b.get_attribute('alt'),\n",
    "            'source':c.get_attribute('innerText'),\n",
    "            'time_stamp':d.get_attribute('innerText'),\n",
    "        })\n",
    "\n",
    "\n",
    "def getContent():\n",
    "    for i in range(len(listData)):\n",
    "        if 'pants-fire' in listData[i]['label'] or 'false' in listData[i]['label'] or 'barely-true' in listData[i]['label']:\n",
    "            driver.get(listData[i]['link'])\n",
    "        \n",
    "            try:\n",
    "                WebDriverWait(driver, 3).until(\n",
    "                    EC.presence_of_element_located(\n",
    "                        (By.CSS_SELECTOR, 'h2[class=\"c-title c-title--subline\"]')\n",
    "                    )\n",
    "                )\n",
    "                #clarify_statement\n",
    "                a_elms = driver.find_elements(By.CSS_SELECTOR, 'h2[class=\"c-title c-title--subline\"]')\n",
    "                for a in a_elms:\n",
    "                    listData[i]['clarify_statement'] = a.get_attribute('innerText')\n",
    "            except TimeoutException as e:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\"\"\"            \n",
    "def saveJason():\n",
    "    fp = open('livercancer.json', 'w', encoding = 'utf-8')\n",
    "    fp.write(json.dumps(listData, ensure_ascii = False))\n",
    "    fp.close()\n",
    "\"\"\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a473d616-78da-4763-80b7-54a6d962b01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accessing to url...\n",
      "0. Crawling...\n",
      "1. Accessing to url...\n",
      "1. Crawling...\n",
      "2. Accessing to url...\n",
      "2. Crawling...\n",
      "3. Accessing to url...\n",
      "3. Crawling...\n",
      "4. Accessing to url...\n",
      "4. Crawling...\n",
      "5. Accessing to url...\n",
      "5. Crawling...\n",
      "6. Accessing to url...\n",
      "6. Crawling...\n",
      "7. Accessing to url...\n",
      "7. Crawling...\n",
      "8. Accessing to url...\n",
      "8. Crawling...\n",
      "9. Accessing to url...\n",
      "9. Crawling...\n",
      "10. Accessing to url...\n",
      "10. Crawling...\n",
      "11. Accessing to url...\n",
      "11. Crawling...\n",
      "12. Accessing to url...\n",
      "12. Crawling...\n",
      "13. Accessing to url...\n",
      "13. Crawling...\n",
      "14. Accessing to url...\n",
      "14. Crawling...\n",
      "15. Accessing to url...\n",
      "15. Crawling...\n",
      "16. Accessing to url...\n",
      "16. Crawling...\n",
      "17. Accessing to url...\n",
      "17. Crawling...\n",
      "18. Accessing to url...\n",
      "18. Crawling...\n",
      "19. Accessing to url...\n",
      "19. Crawling...\n",
      "20. Accessing to url...\n",
      "20. Crawling...\n",
      "21. Accessing to url...\n",
      "21. Crawling...\n",
      "22. Accessing to url...\n",
      "22. Crawling...\n",
      "23. Accessing to url...\n",
      "23. Crawling...\n",
      "24. Accessing to url...\n",
      "24. Crawling...\n",
      "25. Accessing to url...\n",
      "25. Crawling...\n",
      "26. Accessing to url...\n",
      "26. Crawling...\n",
      "27. Accessing to url...\n",
      "27. Crawling...\n",
      "28. Accessing to url...\n",
      "28. Crawling...\n",
      "29. Accessing to url...\n",
      "29. Crawling...\n",
      "30. Accessing to url...\n",
      "30. Crawling...\n",
      "31. Accessing to url...\n",
      "31. Crawling...\n",
      "32. Accessing to url...\n",
      "32. Crawling...\n",
      "33. Accessing to url...\n",
      "33. Crawling...\n",
      "34. Accessing to url...\n",
      "34. Crawling...\n",
      "35. Accessing to url...\n",
      "35. Crawling...\n",
      "36. Accessing to url...\n",
      "36. Crawling...\n",
      "37. Accessing to url...\n",
      "37. Crawling...\n",
      "38. Accessing to url...\n",
      "38. Crawling...\n",
      "39. Accessing to url...\n",
      "39. Crawling...\n",
      "40. Accessing to url...\n",
      "40. Crawling...\n",
      "41. Accessing to url...\n",
      "41. Crawling...\n",
      "42. Accessing to url...\n",
      "42. Crawling...\n",
      "43. Accessing to url...\n",
      "43. Crawling...\n",
      "44. Accessing to url...\n",
      "44. Crawling...\n",
      "45. Accessing to url...\n",
      "45. Crawling...\n",
      "46. Accessing to url...\n",
      "46. Crawling...\n",
      "47. Accessing to url...\n",
      "47. Crawling...\n",
      "48. Accessing to url...\n",
      "48. Crawling...\n",
      "49. Accessing to url...\n",
      "49. Crawling...\n",
      "Crawling cs...\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(f'{i}. Accessing to url...')\n",
    "    visit(i)\n",
    "    print(f'{i}. Crawling...')\n",
    "    getMainLinks()\n",
    "print('Crawling cs...')\n",
    "getContent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "707951d2-6339-4e49-9c58-2de34bbea72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "def saveJason():\n",
    "    fp = open('politifact0731.json', 'w', encoding = 'utf-8')\n",
    "    fp.write(json.dumps(listData, ensure_ascii = False))\n",
    "    fp.close()\n",
    "    print('saved!')\n",
    "saveJason()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07771b-76b5-4706-b64c-5d49b8a631ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "listData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ad3019-d7af-47b8-b83e-8da5c24ee8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read JSON file\n",
    "dataframe = pd.read_json('politifact0731.json')\n",
    "\n",
    "# Print DataFrame\n",
    "dataframe.to_csv('politifact0731.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce706629-71bb-4146-a8f3-c024f951d96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>clarify_statement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>barely-true</th>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false</th>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full-flop</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half-true</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mostly-true</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pants-fire</th>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             content  link  source  time_stamp  clarify_statement\n",
       "label                                                            \n",
       "barely-true      204   204     204         204                204\n",
       "false            822   822     822         822                822\n",
       "full-flop          1     1       1           1                  0\n",
       "half-true        113   113     113         113                  0\n",
       "mostly-true       84    84      84          84                  0\n",
       "pants-fire       222   222     222         222                222\n",
       "true              54    54      54          54                  0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214b3f1a-9451-4770-8990-607cffc3b42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n",
      "(2, 7)\n",
      "(3, 8)\n",
      "(4, 9)\n",
      "(5, 10)\n"
     ]
    }
   ],
   "source": [
    "aaa = [1,2,3,4,5]\n",
    "bbb = [6,7,8,9,10]\n",
    "for i in zip(aaa,bbb):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2d97a9e-b71b-4d46-9d5e-92c6f04bcdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeed!\n"
     ]
    }
   ],
   "source": [
    "expl = 'pants-fire'\n",
    "if 'pants-fire' in expl or 'false' in expl or 'barely-true' in expl:\n",
    "    print('succeed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc44fd-271f-440b-8389-78c775771ede",
   "metadata": {},
   "source": [
    "# Snopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bf41a01-cd7d-43cc-a307-ddcfa1423cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"            \\ndef saveJason():\\n    fp = open('livercancer.json', 'w', encoding = 'utf-8')\\n    fp.write(json.dumps(listData, ensure_ascii = False))\\n    fp.close()\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listData = []\n",
    "url = 'https://www.snopes.com/tag/covid-19/'\n",
    "url2 = 'https://www.snopes.com/tag/covid-19/?pagenum=2'\n",
    "#進入網址\n",
    "def visit(x):\n",
    "    if x == 0 :\n",
    "        driver.get(url)\n",
    "    else:\n",
    "        driver.get(f'https://www.snopes.com/tag/covid-19/?pagenum={x+1}')\n",
    "#找到我們要的內容\n",
    "def getMainLinks():\n",
    "    a_elms = driver.find_elements(By.CSS_SELECTOR, 'h3[class=\"article_title\"]') #title\n",
    "    b_elms = driver.find_elements(By.CSS_SELECTOR, 'a[class=\"outer_article_link_wrapper\"]') #link\n",
    "    c_elms = driver.find_elements(By.CSS_SELECTOR, 'span[class=\"article_date\"]') #time_stamp\n",
    "\n",
    "    for a, b ,c in zip(a_elms, b_elms, c_elms):\n",
    "        listData.append({\n",
    "            'title':a.get_attribute('innerText'),\n",
    "            'link':b.get_attribute('href'),\n",
    "            'time_stamp':c.get_attribute('innerText'),\n",
    "        })\n",
    "\n",
    "\n",
    "def getContent():\n",
    "    for i in range(len(listData)):\n",
    "        driver.get(listData[i]['link'])\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, 'div[class=\"claim_cont\"]')\n",
    "                )\n",
    "            )\n",
    "            a_elms = driver.find_elements(By.CSS_SELECTOR, 'div[class=\"claim_cont\"]') # claims\n",
    "            b_elms = driver.find_elements(By.CSS_SELECTOR, 'div[class=\"rating_title_wrap\"]') # label\n",
    "            c_elms = driver.find_elements(By.CSS_SELECTOR, 'p[class=\"fact_check_info_description\"]') # clarify_statement\n",
    "\n",
    "            for a, b in zip(a_elms, b_elms):\n",
    "                listData[i]['content'] = a.get_attribute('innerText')\n",
    "                listData[i]['label'] = b.text.strip().split('\\n')[0]\n",
    "                \n",
    "            if len(c_elms) > 1 :\n",
    "                listData[i]['clarify_statement'] = c_elms[0].get_attribute('innerText')\n",
    "                listData[i]['clarify_statement2'] = c_elms[1].get_attribute('innerText')\n",
    "            else:\n",
    "                try:\n",
    "                    listData[i]['clarify_statement'] = c_elms[0].get_attribute('innerText')\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "        except TimeoutException as e:\n",
    "            continue\n",
    "\"\"\"            \n",
    "def saveJason():\n",
    "    fp = open('livercancer.json', 'w', encoding = 'utf-8')\n",
    "    fp.write(json.dumps(listData, ensure_ascii = False))\n",
    "    fp.close()\n",
    "\"\"\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6080831-663f-4388-ad9d-52fe09edca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Accessing to url...\n",
      "0. Crawling...\n",
      "1. Accessing to url...\n",
      "1. Crawling...\n",
      "2. Accessing to url...\n",
      "2. Crawling...\n",
      "3. Accessing to url...\n",
      "3. Crawling...\n",
      "4. Accessing to url...\n",
      "4. Crawling...\n",
      "5. Accessing to url...\n",
      "5. Crawling...\n",
      "6. Accessing to url...\n",
      "6. Crawling...\n",
      "7. Accessing to url...\n",
      "7. Crawling...\n",
      "8. Accessing to url...\n",
      "8. Crawling...\n",
      "9. Accessing to url...\n",
      "9. Crawling...\n",
      "10. Accessing to url...\n",
      "10. Crawling...\n",
      "11. Accessing to url...\n",
      "11. Crawling...\n",
      "12. Accessing to url...\n",
      "12. Crawling...\n",
      "13. Accessing to url...\n",
      "13. Crawling...\n",
      "14. Accessing to url...\n",
      "14. Crawling...\n",
      "15. Accessing to url...\n",
      "15. Crawling...\n",
      "16. Accessing to url...\n",
      "16. Crawling...\n",
      "17. Accessing to url...\n",
      "17. Crawling...\n",
      "18. Accessing to url...\n",
      "18. Crawling...\n",
      "19. Accessing to url...\n",
      "19. Crawling...\n",
      "20. Accessing to url...\n",
      "20. Crawling...\n",
      "21. Accessing to url...\n",
      "21. Crawling...\n",
      "22. Accessing to url...\n",
      "22. Crawling...\n",
      "23. Accessing to url...\n",
      "23. Crawling...\n",
      "24. Accessing to url...\n",
      "24. Crawling...\n",
      "25. Accessing to url...\n",
      "25. Crawling...\n",
      "26. Accessing to url...\n",
      "26. Crawling...\n",
      "27. Accessing to url...\n",
      "27. Crawling...\n",
      "28. Accessing to url...\n",
      "28. Crawling...\n",
      "29. Accessing to url...\n",
      "29. Crawling...\n",
      "30. Accessing to url...\n",
      "30. Crawling...\n",
      "31. Accessing to url...\n",
      "31. Crawling...\n",
      "32. Accessing to url...\n",
      "32. Crawling...\n",
      "33. Accessing to url...\n",
      "33. Crawling...\n",
      "34. Accessing to url...\n",
      "34. Crawling...\n",
      "35. Accessing to url...\n",
      "35. Crawling...\n",
      "36. Accessing to url...\n",
      "36. Crawling...\n",
      "37. Accessing to url...\n",
      "37. Crawling...\n",
      "38. Accessing to url...\n",
      "38. Crawling...\n",
      "39. Accessing to url...\n",
      "39. Crawling...\n",
      "40. Accessing to url...\n",
      "40. Crawling...\n",
      "Crawling cs...\n"
     ]
    }
   ],
   "source": [
    "for i in range(41):\n",
    "    print(f'{i}. Accessing to url...')\n",
    "    visit(i)\n",
    "    print(f'{i}. Crawling...')\n",
    "    getMainLinks()\n",
    "print('Crawling cs...')\n",
    "getContent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e633cb-acf3-4ca1-9562-bd1a532a5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "listData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0c8ef8c-753d-4743-8449-0ef8cc55878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "def saveJason():\n",
    "    fp = open('Snopes0831.json', 'w', encoding = 'utf-8')\n",
    "    fp.write(json.dumps(listData, ensure_ascii = False))\n",
    "    fp.close()\n",
    "    print('saved!')\n",
    "saveJason()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95148076-3212-4dfc-9adf-c22a144f25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read JSON file\n",
    "dataframe = pd.read_json('Snopes0831.json')\n",
    "\n",
    "# Print DataFrame\n",
    "dataframe.to_csv('Snopes0831.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb042798-eb0b-4c0f-b5a3-ef696e7a66e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>content</th>\n",
       "      <th>clarify_statement</th>\n",
       "      <th>clarify_statement2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Correct Attribution</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labeled Satire</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misattributed</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miscaptioned</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixture</th>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mostly False</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mostly True</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Originated as Satire</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdated</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scam</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unfounded</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unproven</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  link  time_stamp  content  clarify_statement  \\\n",
       "label                                                                       \n",
       "Correct Attribution      42    42          42       42                  7   \n",
       "False                   243   243         243      243                 25   \n",
       "Labeled Satire           15    15          15       15                  0   \n",
       "Misattributed            12    12          12       12                  0   \n",
       "Miscaptioned             25    25          25       25                  6   \n",
       "Mixture                  91    91          91       91                 91   \n",
       "Mostly False             48    48          48       48                 48   \n",
       "Mostly True              21    21          21       21                 20   \n",
       "Originated as Satire      1     1           1        1                  0   \n",
       "Outdated                  8     8           8        8                  1   \n",
       "Scam                      5     5           5        5                  0   \n",
       "True                    136   136         136      136                 13   \n",
       "Unfounded                 1     1           1        1                  0   \n",
       "Unproven                 25    25          25       25                  8   \n",
       "\n",
       "                      clarify_statement2  \n",
       "label                                     \n",
       "Correct Attribution                    0  \n",
       "False                                  0  \n",
       "Labeled Satire                         0  \n",
       "Misattributed                          0  \n",
       "Miscaptioned                           1  \n",
       "Mixture                               88  \n",
       "Mostly False                          47  \n",
       "Mostly True                           19  \n",
       "Originated as Satire                   0  \n",
       "Outdated                               0  \n",
       "Scam                                   0  \n",
       "True                                   1  \n",
       "Unfounded                              0  \n",
       "Unproven                               3  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547592ea-7887-48dd-84f9-19dc3ca1d630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
